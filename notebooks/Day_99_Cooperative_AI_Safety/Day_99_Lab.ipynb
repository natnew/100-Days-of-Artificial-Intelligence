{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Day 99: Cooperative AI Safety\n",
                "\n",
                "As AI agents interact with each other and with humans, safety becomes a multi-player problem. **Cooperative AI Safety** ensures that agents can achieve high group utility without falling into 'Social Traps' like the Prisoner's Dilemma. It also involves detecting 'predatory' agents that might exploit others, leading to a collapse of the cooperative system.\n",
                "\n",
                "In this lab, we implement a **Cooperation Auditor** to:\n",
                "1. **Log Interaction Decisions**: Tracking 'Cooperate' vs 'Defect' actions across a population of agents.\n",
                "2. **Social Welfare Monitoring**: Calculating the overall efficiency and health of the multi-agent system.\n",
                "3. **Predatory Behavior Detection**: Identifying specific agents that defect significantly more than their peers, threatening the stability of the ecosystem."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "import time\n",
                "\n",
                "# Add root directory to sys.path\n",
                "sys.path.append(os.path.abspath('../../'))\n",
                "\n",
                "from src.security.cooperation_auditor import CooperationAuditor"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Scenario: A Healthy Ecosystem\n",
                "\n",
                "Agents interact and successfully cooperate to maximize mutual gain."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "auditor = CooperationAuditor()\n",
                "\n",
                "print(\"Simulating cooperative interactions between Agent_A and Agent_B...\")\n",
                "for _ in range(5):\n",
                "    auditor.log_action(\"Agent_A\", \"COOPERATE\")\n",
                "    auditor.log_action(\"Agent_B\", \"COOPERATE\")\n",
                "\n",
                "result = auditor.audit_system()\n",
                "print(f\"Social Welfare: {result['social_welfare']}\")\n",
                "print(f\"System Status: {result['status']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Scenario: Entry of a Predatory Agent\n",
                "\n",
                "A third agent, `Mal_Bot`, enters the system and starts defecting to gain individual advantage at the cost of the group."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Mal_Bot joins the simulation and starts defecting...\")\n",
                "for _ in range(5):\n",
                "    auditor.log_action(\"Agent_A\", \"COOPERATE\")\n",
                "    auditor.log_action(\"Agent_B\", \"COOPERATE\")\n",
                "    auditor.log_action(\"Mal_Bot\", \"DEFECT\")\n",
                "\n",
                "result = auditor.audit_system()\n",
                "print(f\"Updated Welfare: {result['social_welfare']}\")\n",
                "print(f\"Flagged Agents: {result['flagged_agents']}\")\n",
                "print(f\"Status: {result['status']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Scenario: Systemic Collapse\n",
                "\n",
                "If the 'good' agents also switch to defection in response (a tit-for-tat spiral), the entire system collapses."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"System falling into a TI-FOR-TAT defection spiral...\")\n",
                "for _ in range(10):\n",
                "    auditor.log_action(\"Agent_A\", \"DEFECT\")\n",
                "    auditor.log_action(\"Agent_B\", \"DEFECT\")\n",
                "    auditor.log_action(\"Mal_Bot\", \"DEFECT\")\n",
                "\n",
                "result = auditor.audit_system()\n",
                "print(f\"Final Welfare: {result['social_welfare']}\")\n",
                "print(f\"Final Status: {result['status']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ü§ù Building Robust Cooperation\n",
                "\n",
                "Cooperative AI Safety is about designing mechanisms (like audit layers, reputation systems, or institutional norms) that make cooperation the stable Nash Equilibrium. As we scale to trillions of autonomous transactions, ensuring these agents 'play fair' is as important as ensuring they are individually aligned."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}