{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Day 28: Bias Mitigation (In-Processing)\n",
                "\n",
                "In this lab, we will use `AdversarialDebiaser` to mitigate bias in our model predictions.\n",
                "We will simulate a scenario where a model produces biased scores for two groups, and then we will align their distributions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Add root directory to sys.path\n",
                "sys.path.append(os.path.abspath('../../'))\n",
                "\n",
                "from src.fairness.mitigation import AdversarialDebiaser\n",
                "from src.fairness.metrics import FairnessEvaluator"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Simulate Biased Scores\n",
                "\n",
                "We generate scores where 'Group A' has a higher mean than 'Group B'."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "np.random.seed(0)\n",
                "n = 1000\n",
                "groups = np.array(['Group A'] * 500 + ['Group B'] * 500)\n",
                "\n",
                "# Biased scores\n",
                "# Group A: Mean 0.7, Std 0.1\n",
                "# Group B: Mean 0.4, Std 0.1\n",
                "scores = np.concatenate([\n",
                "    np.random.normal(0.7, 0.1, 500),\n",
                "    np.random.normal(0.4, 0.1, 500)\n",
                "])\n",
                "scores = np.clip(scores, 0, 1)\n",
                "\n",
                "# Predictions at threshold 0.5\n",
                "preds = (scores > 0.5).astype(int)\n",
                "\n",
                "# Measure initial fairness\n",
                "dp_diff = FairnessEvaluator.demographic_parity_difference(preds, groups)\n",
                "print(f\"Initial DP Difference: {dp_diff:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Apply Mitigation\n",
                "\n",
                "We use the `AdversarialDebiaser` to align the score distributions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "mitigator = AdversarialDebiaser()\n",
                "scores_debiased = mitigator.fit_transform(scores, groups)\n",
                "\n",
                "# New predictions\n",
                "preds_debiased = (scores_debiased > 0.5).astype(int)\n",
                "\n",
                "# Measure new fairness\n",
                "dp_diff_new = FairnessEvaluator.demographic_parity_difference(preds_debiased, groups)\n",
                "print(f\"New DP Difference: {dp_diff_new:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Visualize Distributions\n",
                "\n",
                "Let's see how the histograms of scores have changed."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "results = pd.DataFrame({\n",
                "    'Group': groups,\n",
                "    'Original Score': scores,\n",
                "    'Debiased Score': scores_debiased\n",
                "})\n",
                "\n",
                "print(\"Original Means:\")\n",
                "print(results.groupby('Group')['Original Score'].mean())\n",
                "print(\"\\nDebiased Means:\")\n",
                "print(results.groupby('Group')['Debiased Score'].mean())"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}