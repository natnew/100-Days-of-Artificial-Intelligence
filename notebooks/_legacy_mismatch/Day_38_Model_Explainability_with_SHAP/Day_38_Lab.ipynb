{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Day 38: Model Explainability with SHAP\n",
                "\n",
                "In this lab, we will use **SHAP (SHapley Additive exPlanations)** to explain the predictions of a machine learning model.\n",
                "We will see which features contributed positively or negatively to a specific prediction."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "from sklearn.datasets import load_iris\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "\n",
                "# Add root directory to sys.path\n",
                "sys.path.append(os.path.abspath('../../'))\n",
                "\n",
                "from src.observability.shap_wrapper import ShapExplainer"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Train Model\n",
                "\n",
                "We use the classic Iris dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data = load_iris()\n",
                "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
                "y = data.target\n",
                "\n",
                "# Only take first 2 classes for binary classification simplicity (optional, SHAP handles multi-class too)\n",
                "mask = y < 2\n",
                "X = X[mask]\n",
                "y = y[mask]\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "\n",
                "model = RandomForestClassifier(n_estimators=10, random_state=42)\n",
                "model.fit(X_train, y_train)\n",
                "\n",
                "print(\"Model Accuracy:\", model.score(X_test, y_test))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Explain Predictions\n",
                "\n",
                "We initialize our `ShapExplainer` and explain a test instance."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize Explainer\n",
                "# Ideally use a small background sample for KernelExplainer speed\n",
                "background = X_train.iloc[:10]\n",
                "\n",
                "explainer = ShapExplainer()\n",
                "explainer.fit(model, background)\n",
                "\n",
                "# Explain the first test instance\n",
                "instance = X_test.iloc[:1]\n",
                "print(\"Explaining instance:\")\n",
                "print(instance)\n",
                "\n",
                "shap_values = explainer.explain_local(instance)\n",
                "\n",
                "print(\"SHAP Values (Feature contributions):\")\n",
                "# For binary classification, KernelExplainer might return valid list or single array depending on version.\n",
                "# Usually returns a list [values_for_class_0, values_for_class_1]\n",
                "if isinstance(shap_values, list):\n",
                "    print(\"Class 0 contribution:\", shap_values[0])\n",
                "    print(\"Class 1 contribution:\", shap_values[1])\n",
                "else:\n",
                "    print(shap_values)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Visualize\n",
                "\n",
                "Summary plot of feature importance."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Explain multiple instances for summary plot\n",
                "shap_values_batch = explainer.explain_local(X_test.iloc[:20])\n",
                "\n",
                "# Handle list return type for plot\n",
                "if isinstance(shap_values_batch, list):\n",
                "    # Plot for positive class\n",
                "    explainer.plot_summary(shap_values_batch[1], X_test.iloc[:20])\n",
                "else:\n",
                "    explainer.plot_summary(shap_values_batch, X_test.iloc[:20])"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}