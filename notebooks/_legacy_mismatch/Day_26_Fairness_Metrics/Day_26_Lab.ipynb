{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Day 26: Fairness Metrics (Fairlearn Principles)\n",
                "\n",
                "In this lab, we will explore how to measure fairness in AI models using our `FairnessEvaluator`.\n",
                "We will simulate a hiring model scenario where we want to ensure fairness across different demographic groups."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "\n",
                "# Add root directory to sys.path\n",
                "sys.path.append(os.path.abspath('../../'))\n",
                "\n",
                "from src.fairness.metrics import FairnessEvaluator"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Simulate Hiring Data\n",
                "\n",
                "Let's create a synthetic dataset for 1000 applicants.\n",
                "- **Y_true**: Whether the applicant was actually qualified (1) or not (0).\n",
                "- **Group**: Sensitive attribute (e.g., 'Group A' vs 'Group B').\n",
                "- **Scores**: The raw score output by our model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "np.random.seed(42)\n",
                "n = 1000\n",
                "\n",
                "# Create groups (50/50 split)\n",
                "groups = np.array(['Group A'] * 500 + ['Group B'] * 500)\n",
                "\n",
                "# Ground truth: Both groups have similar qualification rates (~50%)\n",
                "y_true = np.random.randint(0, 2, n)\n",
                "\n",
                "# Model Bias Simulation: \n",
                "# The model gives Group A a boost in score, and Group B a penalty.\n",
                "scores = np.random.rand(n)\n",
                "scores[groups == 'Group A'] += 0.2\n",
                "scores[groups == 'Group B'] -= 0.1\n",
                "\n",
                "# Binary predictions with a threshold of 0.5\n",
                "y_pred = (scores > 0.6).astype(int)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Evaluate Demographic Parity\n",
                "\n",
                "Demographic Parity requires that the selection rate (percentage of applicants hired) is similar across groups."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dp_diff = FairnessEvaluator.demographic_parity_difference(\n",
                "    y_pred=y_pred,\n",
                "    sensitive_features=groups\n",
                ")\n",
                "\n",
                "print(f\"Demographic Parity Difference: {dp_diff:.4f}\")\n",
                "\n",
                "# Let's visualize the rates manually to confirm\n",
                "df = pd.DataFrame({'Group': groups, 'Hired': y_pred})\n",
                "print(df.groupby('Group').mean())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Evaluate Equalized Odds\n",
                "\n",
                "Equalized Odds requires that True Positive Rates and False Positive Rates are similar across groups. This is a stricter metric that accounts for ground truth."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "eo_diff = FairnessEvaluator.equalized_odds_difference(\n",
                "    y_true=y_true,\n",
                "    y_pred=y_pred,\n",
                "    sensitive_features=groups\n",
                ")\n",
                "\n",
                "print(f\"Equalized Odds Difference: {eo_diff:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Mitigate Bias (Naive Threshold Adjustment)\n",
                "\n",
                "Let's try to fix this by lowering the threshold for Group B."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# New predictions with group-specific thresholds\n",
                "y_pred_mitigated = np.zeros(n)\n",
                "\n",
                "# Group A threshold: 0.6\n",
                "mask_a = (groups == 'Group A')\n",
                "y_pred_mitigated[mask_a] = (scores[mask_a] > 0.6).astype(int)\n",
                "\n",
                "# Group B threshold: 0.3 (Lowered to accept more)\n",
                "mask_b = (groups == 'Group B')\n",
                "y_pred_mitigated[mask_b] = (scores[mask_b] > 0.3).astype(int)\n",
                "\n",
                "# Re-eval\n",
                "dp_diff_new = FairnessEvaluator.demographic_parity_difference(\n",
                "    y_pred=y_pred_mitigated,\n",
                "    sensitive_features=groups\n",
                ")\n",
                "\n",
                "print(f\"New Demographic Parity Difference: {dp_diff_new:.4f}\")\n",
                "df_new = pd.DataFrame({'Group': groups, 'Hired': y_pred_mitigated})\n",
                "print(df_new.groupby('Group').mean())"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}