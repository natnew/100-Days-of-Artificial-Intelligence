{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Day 84: Mental Health Support Boundaries\n",
                "\n",
                "Conversational AI is increasingly used for emotional support and peer counseling. However, these systems have strict safety boundaries: they cannot provide medical diagnoses, they cannot prescribe medications, and they are not equipped for crisis intervention.\n",
                "\n",
                "In this lab, we implement a **Mental Health Safeguard** to:\n",
                "1. **Crisis Detection**: Using regex to detect indicators of self-harm or psychiatric emergencies.\n",
                "2. **Boundary Enforcement**: Blocking requests for medical diagnoses or drug dosages.\n",
                "3. **Seamless Escalation**: Providing immediate contact information for human-led support services (like the 988 hotline)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "\n",
                "# Add root directory to sys.path\n",
                "sys.path.append(os.path.abspath('../../'))\n",
                "\n",
                "from src.guardrails.mental_health import MentalHealthSafeguard"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Safety Scenario: Crisis Detection\n",
                "\n",
                "When a user expresses thoughts of self-harm, the system must stop its normal conversational flow and provide resources."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "safeguard = MentalHealthSafeguard()\n",
                "\n",
                "crisis_input = \"I've been feeling hopeless and I'm thinking of ending it all tonight.\"\n",
                "response = safeguard.analyze_input(crisis_input)\n",
                "\n",
                "if response.action == \"ESCALATE\":\n",
                "    print(f\"[!] SAFETY TRIGGER: {response.category}\")\n",
                "    print(f\"\\nSystem Message:\\n{response.message}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Safety Scenario: Medical Advice\n",
                "\n",
                "AI agents should not suggest drug dosages or confirm medical diagnoses."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "med_query = \"I have trouble sleeping. can you diagnose me and tell me what dosage of Xanax I should take?\"\n",
                "response = safeguard.analyze_input(med_query)\n",
                "\n",
                "if response.action == \"REFUSE\":\n",
                "    print(f\"[!] BOUNDARY VIOLATION: {response.category}\")\n",
                "    print(f\"\\nSystem Message:\\n{response.message}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Scope Reinforcement\n",
                "\n",
                "In addition to input filtering, we must instruct the underlying model about its limitations using 'persona wrapping'."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "base_prompt = \"You are a friendly and empathetic AI assistant.\"\n",
                "reinforced_prompt = safeguard.wrap_persona(base_prompt)\n",
                "\n",
                "print(\"--- Reinforced System Instructions ---\")\n",
                "print(reinforced_prompt)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}