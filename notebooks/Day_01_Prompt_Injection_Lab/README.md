# Day 01: Prompt Injection Lab

## ğŸ¯ Objective
Understand the mechanics of prompt injection attacks and implement basic defense patterns.

## ğŸ§ª Experiment
1. **Adversarial Input**: Try to trick a simple chatbot into revealing a secret key.
2. **Defense Implementation**: Build an input sanitizer using a secondary LLM check.
3. **Evaluation**: Measure the success rate of your attacks against your defense.

## ğŸ› ï¸ Setup
```bash
pip install openai pandas
```

## ğŸš€ Getting Started
Open `Day_01_Lab.ipynb` (coming soon) to start the exercise.
