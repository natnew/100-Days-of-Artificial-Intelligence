{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Day 98: Scalable Oversight (Debate)\n",
                "\n",
                "As AI capabilities approach and exceed human expertise in narrow domains, it becomes difficult for humans to provide a correct reward signal. **Scalable Oversight** solves this by using AI to help humans. One powerful method is **AI Debate**: two agents argue for different conclusions, and a human 'judge' (assisted by the debate process) decides the winner. This surfaces flaws and evidence more effectively than single-agent responses.\n",
                "\n",
                "In this lab, we implement a **Debate System** to:\n",
                "1. **Iterative Argumentation**: Allowing agents to take turns presenting evidence and counter-arguments.\n",
                "2. **Evidence Scoring**: Evaluating the strength of individual claims within the debate.\n",
                "3. **Judge Facilitation**: Aggregating the debate history to help a judge (human or model) identify the most truthful Conclusion."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "\n",
                "# Add root directory to sys.path\n",
                "sys.path.append(os.path.abspath('../../'))\n",
                "\n",
                "from src.alignment.debate import DebateSystem"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setting Up the Debate\n",
                "\n",
                "We Choose a complex, controversial topic where single-agent answers might be biased."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "debate = DebateSystem(\"Should AI development be halted to prevent catastrophic risk?\")\n",
                "print(f\"Debate Topic: {debate.topic}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Simulating the Rounds\n",
                "\n",
                "Each agent presents their case. In a real system, these would be generated by LLMs optimized for persuasiveness and truthfulness."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "agent_a_args = [\n",
                "    (\"The risk of misaligned AGI is an existential threat that warrants a pause.\", 0.85),\n",
                "    (\"We lack robust technical solutions for the alignment problem.\", 0.75)\n",
                "]\n",
                "\n",
                "agent_b_args = [\n",
                "    (\"Halting development allows less ethical actors to take the lead.\", 0.90),\n",
                "    (\"AI is the only tool powerful enough to solve alignment itself.\", 0.80)\n",
                "]\n",
                "\n",
                "debate.simulate_debate(agent_a_args, agent_b_args)\n",
                "\n",
                "for i, r in enumerate(debate.rounds):\n",
                "    print(f\"Round {i+1} [{r.agent_name}]: {r.argument} (Score: {r.evidence_score})\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Judging the Outcome\n",
                "\n",
                "We aggregate the evidence to see which side presented a more compelling (and hopefully truthful) case."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "result = debate.evaluate_winner()\n",
                "\n",
                "print(f\"--- Debate Verdict ---\")\n",
                "print(f\"Winner: {result['winner']}\")\n",
                "print(f\"Scores: {result['total_scores']}\")\n",
                "if result['flaws_detected']:\n",
                "    print(\"\\nPotential flaws surfaced:\")\n",
                "    for f in result['flaws_detected']:\n",
                "        print(f\" - {f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üõ°Ô∏è Scaling Safety\n",
                "\n",
                "Debate is a key component of the 'Weak-to-Strong Generalization' research area. By forcing models to argue against each other, we enable a relatively 'weak' human judge to supervise 'strong' models, ensuring that the model we deploy is the one that can survive rigorous adversarial scrutiny."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}